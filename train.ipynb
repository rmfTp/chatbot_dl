{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ebd45a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\project\\chatbot_dl\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\project\\chatbot_dl\\.venv\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import TFGPT2LMHeadModel\n",
    "import torch\n",
    "import pandas as pd\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e674f0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\project\\chatbot_dl\\.venv\\Lib\\site-packages\\tf_keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TensorFlow and JAX classes are deprecated and will be removed in Transformers v5. We recommend migrating to PyTorch classes or pinning your version of Transformers.\n",
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFGPT2LMHeadModel: ['transformer.h.8.attn.masked_bias', 'transformer.h.2.attn.masked_bias', 'transformer.h.9.attn.masked_bias', 'transformer.h.6.attn.masked_bias', 'transformer.h.5.attn.masked_bias', 'transformer.h.10.attn.masked_bias', 'transformer.h.7.attn.masked_bias', 'transformer.h.3.attn.masked_bias', 'transformer.h.11.attn.masked_bias', 'transformer.h.4.attn.masked_bias', 'transformer.h.0.attn.masked_bias', 'transformer.h.1.attn.masked_bias', 'lm_head.weight']\n",
      "- This IS expected if you are initializing TFGPT2LMHeadModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFGPT2LMHeadModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFGPT2LMHeadModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('skt/kogpt2-base-v2', bos_token='<s>', eos_token='</s>', pad_token='<pad>')\n",
    "model = TFGPT2LMHeadModel.from_pretrained('skt/kogpt2-base-v2', from_pt=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2152bd6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"tfgpt2lm_head_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " transformer (TFGPT2MainLay  multiple                  125164032 \n",
      " er)                                                             \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 125164032 (477.46 MB)\n",
      "Trainable params: 125164032 (477.46 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "07186a82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51200"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1897f068",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q</th>\n",
       "      <th>A</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12시 땡!</td>\n",
       "      <td>하루가 또 가네요.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1지망 학교 떨어졌어</td>\n",
       "      <td>위로해 드립니다.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3박4일 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3박4일 정도 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PPL 심하네</td>\n",
       "      <td>눈살이 찌푸려지죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Q            A  label\n",
       "0           12시 땡!   하루가 또 가네요.      0\n",
       "1      1지망 학교 떨어졌어    위로해 드립니다.      0\n",
       "2     3박4일 놀러가고 싶다  여행은 언제나 좋죠.      0\n",
       "3  3박4일 정도 놀러가고 싶다  여행은 언제나 좋죠.      0\n",
       "4          PPL 심하네   눈살이 찌푸려지죠.      0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1 = pd.read_csv('data/data1.csv')\n",
    "data1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3da5c9d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>req</th>\n",
       "      <th>res</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>너 좋아하는 차 종류 있어?</td>\n",
       "      <td>무슨 차? 자동차? 마시는 차?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ㅋㅋ 마시는 차 말한 거야!</td>\n",
       "      <td>아하 나 둥글레, 옥수수, 보리차 좋아해</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>완전 곡물류 좋아하네 ㅋㅋ</td>\n",
       "      <td>야쓰 끓이기 귀찮아서 냉침해 먹어</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>그럼 오래 걸리지 않아?</td>\n",
       "      <td>끓이는 것보다는 훨씬 오래 걸리지 ㅠ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>근데 냉침 하는 것도 귀찮겠다 ㅜㅠ</td>\n",
       "      <td>응! 그래서 매일은 안 먹고 가끔 마셔</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   req                     res\n",
       "0      너 좋아하는 차 종류 있어?       무슨 차? 자동차? 마시는 차?\n",
       "1      ㅋㅋ 마시는 차 말한 거야!  아하 나 둥글레, 옥수수, 보리차 좋아해\n",
       "2       완전 곡물류 좋아하네 ㅋㅋ      야쓰 끓이기 귀찮아서 냉침해 먹어\n",
       "3        그럼 오래 걸리지 않아?    끓이는 것보다는 훨씬 오래 걸리지 ㅠ\n",
       "4  근데 냉침 하는 것도 귀찮겠다 ㅜㅠ   응! 그래서 매일은 안 먹고 가끔 마셔"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2 = pd.read_csv('data/data2.csv')\n",
    "data2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "79436976",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100797"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_data = list(zip(data1['Q'].to_list(),data1['A'].to_list()))\n",
    "chat_data2 = list(zip(data2['req'].to_list(),data2['res'].to_list()))\n",
    "chat_data.extend(chat_data2)\n",
    "len(chat_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "244b2541",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_chat_data():\n",
    "    bos_token = tokenizer.bos_token\n",
    "    eos_token = tokenizer.eos_token\n",
    "    for question, answer in chat_data:\n",
    "        sent = f'{bos_token}<usr>{question}<sys>{answer}{eos_token}'\n",
    "        yield tokenizer.encode(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bbd1f8a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 2, 9349, 7888, 739, 7318, 376, 4, 12557, 6824, 9108, 9028, 7098, 25856, 1]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen = get_chat_data()\n",
    "next(gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "02cd9074",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "dataset = tf.data.Dataset.from_generator(get_chat_data, output_types=tf.int32)\n",
    "\n",
    "dataset = dataset.padded_batch(batch_size=batch_size,padded_shapes=(None,),padding_values=tokenizer.pad_token_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1fdf6c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "adam = keras.optimizers.Adam(learning_rate=3e-5, epsilon=1e-8)\n",
    "steps = len(chat_data) // batch_size\n",
    "epochs = 1\n",
    "for epoch in range(epochs):\n",
    "    train_loss = 0\n",
    "\n",
    "    for batch in dataset:\n",
    "        with tf.GradientTape() as tape:\n",
    "            result = model(batch, labels=batch)\n",
    "            batch_loss = tf.reduce_mean(result[0])\n",
    "        train_loss += batch_loss\n",
    "    train_loss /= steps\n",
    "    print(f'epoch:{epoch+1}, loss={train_loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8aa54c90",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'TFGPT2LMHeadModel' object has no attribute 'save_weight'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[22]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43msave_weight\u001b[49m(\u001b[33m'\u001b[39m\u001b[33mchatbot.weight.h5\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mAttributeError\u001b[39m: 'TFGPT2LMHeadModel' object has no attribute 'save_weight'"
     ]
    }
   ],
   "source": [
    "model.save_weight('chatbot.weight.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1e1912b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 2, 14821, 8135, 15495, 14841, 7172, 406, 4]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = '<s><usr>밥은 먹고 다니니?<sys>'\n",
    "input_ids = tokenizer.encode(text)\n",
    "input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5e2d10b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<s><usr> 밥은 먹고 다니니?<sys>\"은 이렇게 물었다.\\n\"그래요.\" 밥이 대답하자, 그건 뭔가 이상했다.\\n\"아, 그런 일은 어디 있니?\" 밥이 말했다.\\n밥은 대답 없이 고개를 끄덕였다.\\n그런데 그 말은 바로 자기 자신의 마음이었다.\\n밥은 대답 없이 말했다.\\n\"그게 뭔지 모르겠군요.\" 밥이 대답했다.\\n\"아니, 무슨 일이지?\"\\n밥이 대답하자, 밥은 이렇게 대답했다.\\n\"이것 역시 내 마음이야.\"\\n'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids = tf.convert_to_tensor([input_ids])\n",
    "outputs = model.generate(input_ids, max_length=100, do_sample=True, top_k=20)\n",
    "tokenizer.decode(outputs[0].numpy().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7d2ecd51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chatbot(user_text):\n",
    "    input_ids = tokenizer.encode(f'<s><usr>{user_text}<sys>')\n",
    "    input_ids = tf.convert_to_tensor([input_ids])\n",
    "    outputs = model.generate(input_ids, max_length=100, do_sample=True, top_k=100, top_p=0.9)\n",
    "    sentence = tokenizer.decode(outputs[0].numpy().tolist())\n",
    "    return sentence.split('<sys>')[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "34e555c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'에요?\\n다음으로 캬~ 캬~! 예~ 자 이거 두 번째 이야기부터 해주셔야돼요?!\\n와~ 캬~ 캬~ 캬~ 캬~ 캬~ 와~ 와~ 와~ 자 여기 보니까 캬~ 캬~ 진짜 대박 입었어요?!\\n와~ 와~ 캬~ 캬~ 캬~ 음~ 캬~ 다들 먹고'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatbot('오늘 저녁 메뉴 추천해줘')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "763e0998",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
